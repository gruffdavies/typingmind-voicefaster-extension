<!DOCTYPE html>
<html>

<head>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css">
    <style>
        :root {
            /* Core brand/identity */
            --primary: rgba(64, 169, 255, 1);
            --primary-bright: rgba(64, 169, 255, 0.8);
            --primary-muted: rgba(64, 169, 255, 0.6);
            --primary-subtle: rgba(64, 169, 255, 0.4);
            --primary-faint: rgba(64, 169, 255, 0.3);
            --primary-ghost: rgba(64, 169, 255, 0.2);

            /* Interface elements */
            --surface-floating: rgba(0, 0, 0, 0.1);
            --surface-raised: rgba(0, 0, 0, 0.2);
            --surface-deep: rgba(0, 0, 0, 0.3);

            /* States */
            --vis-idle-glow: var(--primary-subtle);
            --vis-idle-pulse: var(--primary-faint);
            --vis-listening: rgba(120, 255, 100, 0.6);
            --vis-speaking: rgba(0, 215, 255, 0.8);
            --state-active: rgba(255, 64, 64, 0.3);
            --state-idle: var(--primary-ghost);
            --state-listening: var(--state-active);
            --state-speaking: var(--primary-bright);

            /* Text */
            --text-primary: var(--primary-bright);
            --text-secondary: var(--primary-muted);
            --text-status: var(--primary-muted);
            --text-transcript: var(--vis-listening);

            /* Visual elements */
            --glow-core: var(--primary-subtle);
            --glow-outer: var(--primary-faint);
            --wave-intensity: var(--primary-bright);
            --bars-intensity: var(--primary-muted);

            /* UI Symbols */
            --symbol-mic: "bi-mic-fill";
            --symbol-mic-muted: "bi-mic-mute-fill";
            --symbol-settings: "bi-gear-fill";
        }

        .controls button i {
            font-size: 1.2em;
            /* Adjust size as needed */
            line-height: 1;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        body {
            margin: 0;
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            background: #1a1a1a;
            font-family: Arial, sans-serif;
        }

        #voicefaster-player {
            position: fixed;
            right: 20px;
            top: 20px;
            padding: 8px;
            border-radius: 12px;
            background: var(--surface-floating);
            backdrop-filter: blur(8px);
            display: flex;
            flex-direction: column;
            gap: 8px;
            transition: all 0.3s ease;
            z-index: 1000;
            cursor: move;
            user-select: none;
        }

        .voicefaster {
            --surface-floating: rgba(0, 0, 0, 0.1);
            --surface-raised: rgba(0, 0, 0, 0.2);
            --primary: rgba(64, 169, 255, 1);
            --primary-muted: rgba(64, 169, 255, 0.6);
        }

        .voicefaster-queue-item {
            display: flex;
            align-items: center;
            gap: 8px;
            padding: 8px;
            border-radius: 4px;
            background: var(--surface-floating);
            cursor: pointer;
            transition: all 0.2s ease;
        }

        .voicefaster-queue-item:hover {
            background: var(--surface-raised);
        }

        .voicefaster-progress {
            position: relative;
            height: 2px;
            background: var(--surface-raised);
            overflow: hidden;
        }

        .voicefaster-progress-bar {
            position: absolute;
            left: 0;
            top: 0;
            height: 100%;
            background: var(--primary);
            transition: width 0.1s linear;
        }

        .player-header {
            display: flex;
            align-items: center;
            gap: 8px;
            cursor: move;
        }

        /* Controls Section */
        .controls {
            display: flex;
            gap: 8px;
            opacity: 1;
            /* Changed from 0 to always show controls */
        }

        .controls button {
            width: 32px;
            height: 32px;
            padding: 0;
            display: flex;
            align-items: center;
            justify-content: center;
            background: var(--state-idle);
            border: none;
            border-radius: 4px;
            color: var(--text-primary);
            cursor: pointer;
            transition: all 0.3s ease;
        }

        /* Mic Button Specific Styles */
        #mic-button {
            position: relative;
            opacity: 1;
        }

        #mic-button.active {
            background: var(--state-active);
        }

        #mic-button:hover {
            background: var(--primary-faint);
        }

        /* Settings Button Specific Styles */
        #settings-button {
            background: var(--surface-raised);
        }

        #settings-button:hover {
            background: var(--surface-deep);
        }

        /* Transcript Area */
        #transcript-area {
            display: none;
            width: 300px;
            min-height: 100px;
            max-height: 200px;
            border-radius: 8px;
            padding: 10px;
            margin-top: 8px;
            background: var(--surface-raised);
            color: var(--text-transcript);
            font-size: 14px;
            line-height: 1.4;
            overflow-y: auto;
            transition: all 0.3s ease;
        }

        #transcript-area.active {
            display: block;
        }

        .transcript-controls {
            display: flex;
            justify-content: flex-end;
            gap: 8px;
            margin-top: 8px;
        }

        .transcript-controls button {
            padding: 6px 12px;
            border: none;
            border-radius: 4px;
            background: var(--surface-raised);
            color: var(--text-primary);
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 12px;
            display: flex;
            align-items: center;
            gap: 4px;
        }

        .transcript-controls button:hover {
            background: var(--primary-faint);
            transform: translateY(-1px);
        }

        .transcript-controls button:active {
            transform: translateY(0px);
        }

        #send-transcript {
            background: var(--primary-subtle);
        }

        #send-transcript:hover {
            background: var(--primary-muted);
        }

        #clear-transcript {
            background: var(--surface-deep);
        }

        /* Status Indicator */
        #status-indicator {
            font-size: 12px;
            color: var(--text-status);
            margin-left: 8px;
        }

        /* Demo Controls (if still needed) */
        #demo-controls {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            display: flex;
            gap: 10px;
            padding: 15px;
            background: var(--surface-floating);
            border-radius: 8px;
            backdrop-filter: blur(8px);
        }

        #demo-controls button {
            padding: 8px 16px;
            border: none;
            border-radius: 4px;
            background: var(--state-idle);
            color: var(--text-primary);
            cursor: pointer;
            transition: all 0.3s ease;
        }

        #demo-controls button:hover {
            background: var(--primary-faint);
        }

        /* Sample Text (if still needed) */
        #sample-text {
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            max-width: 600px;
            padding: 20px;
            color: #888;
            line-height: 1.6;
            text-align: justify;
        }

        /* Utility Classes */
        .state-transition {
            transition: all 0.3s ease-in-out;
        }
    </style>
</head>

<body>
    <!-- Sample text to demonstrate overlay -->
    <div id="sample-text">
        Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore
        magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
        consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla
        pariatur.
    </div>

    <!-- Demo controls -->
    <div id="demo-controls">
        <button onclick="visualizer.setMode('idle')">Idle</button>
        <button onclick="visualizer.setMode('listening')">Listening</button>
        <button onclick="visualizer.setMode('speaking')">Speaking</button>
    </div>

    <script src="secrets.js" type="text/javascript"></script>
    <script>
        // Font Awesome classes
        const ICONS = {
            mic: 'fas fa-microphone',
            micMuted: 'fas fa-microphone-slash',
            settings: 'fas fa-cog'
        };

        class AudioStream {
            constructor(streamRequestResponse) {
                this.id = generate_uuid();
                this.url = streamRequestResponse.url;
                this.headers = streamRequestResponse.headers;
                this.method = streamRequestResponse.method;
                this.body = streamRequestResponse.body;

                // Parse the text from the body
                try {
                    const bodyJson = JSON.parse(this.body);
                    this.text = bodyJson.text || '';
                } catch (e) {
                    this.text = '';
                }

                this.state = "queued";
                this.startTime = null;
                this.endTime = null;
                this.progress = 0; // Add progress tracking
            }
        }

        class QueueManager {
            constructor(audioPlayer, visualizer) {
                this.audioPlayer = audioPlayer;
                this.visualizer = visualizer;
                this.expanded = false;
            }

            toggleExpansion() {
                this.expanded = !this.expanded;
                if (this.expanded) {
                    this.visualizer.expandWithQueue();
                } else {
                    this.visualizer.shrink();
                }
            }

            jumpToItem(id) {
                const stream = this.audioPlayer.queue.find(stream => stream.id === id);
                if (stream) {
                    this.audioPlayer.stop();
                    this.audioPlayer.playStream(stream);
                }
            }

            updateProgress(id, progress) {
                const stream = this.audioPlayer.queue.find(stream => stream.id === id);
                if (stream) {
                    stream.progress = progress;
                    this.visualizer.updateProgress(id, progress);
                }
            }
        }
        class AudioVisualizer {
            constructor(container, config = {}) {
                this.finalTranscript = '';
                this.interimTranscript = '';
                this.events = new Map();
                this.config = {
                    fftSize: config.fftSize || 256,
                    canvasSize: config.canvasSize || 48,
                    barCount: config.barCount || 20,
                    ...config // spread operator to merge default and user-defined configs
                };
                this.container = container;
                this.canvas = document.createElement("canvas");
                this.ctx = this.canvas.getContext("2d");
                this.mode = "idle";
                this.transcriptActive = false;
                this.styles = getComputedStyle(document.documentElement);
                this.setupCanvas();
                this.startAnimation();

                // Audio analysis setup
                this.audioContext = null;
                this.analyser = null;
                this.bufferLength = null;
                this.dataArray = null;

                // For speaking mode
                this.playbackAnalyser = null;
                this.playbackDataArray = null;

                this.isMuted = false;

                const DEEPGRAM_API_KEY = secrets.deepgramApiKey;
                console.log("DEEPGRAM_API_KEY", DEEPGRAM_API_KEY);

                this.ws = new WebSocket("wss://api.deepgram.com/v1/listen", [
                    "token",
                    secrets.deepgramApiKey
                ]);
                this.ws.onopen = () => {
                    this.ws.send(JSON.stringify({
                        type: "Authorization",
                        token: secrets.deepgramApiKey
                    }));
                };

                // Add WebSocket handlers
                this.ws.onmessage = (event) => {
                    const response = JSON.parse(event.data);
                    if (response.type === "Results") {
                        const transcript = response.channel.alternatives[0].transcript;
                        if (response.is_final) {
                            this.finalTranscript += transcript + ' ';
                            this.interimTranscript = '';
                        } else {
                            this.interimTranscript = transcript;
                        }
                        this.updateTranscript(this.finalTranscript + this.interimTranscript);
                    }
                };
            }

            // Add to AudioVisualizer class
            cleanup() {
                if (this.ws) {
                    this.ws.close();
                }
                if (this.currentStream) {
                    this.currentStream.getTracks().forEach(track => track.stop());
                }
            }


            async setupRecording() {
                try {
                    // Initialize audio context only when needed
                    if (!this.audioContext) {
                        this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                        this.analyser = this.audioContext.createAnalyser();
                        this.analyser.fftSize = 256;
                        this.bufferLength = this.analyser.frequencyBinCount;
                        this.dataArray = new Uint8Array(this.bufferLength);
                    }

                    // Now we can safely check the state
                    if (this.audioContext && this.audioContext.state === "suspended") {
                        await this.audioContext.resume();
                    }

                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    this.currentStream = stream;
                    const source = this.audioContext.createMediaStreamSource(stream);
                    source.connect(this.analyser);

                    // Add Deepgram streaming
                    const mediaRecorder = new MediaRecorder(stream);
                    mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0 && this.ws.readyState === 1) {
                            event.data.arrayBuffer().then(buffer => {
                                this.ws.send(buffer);
                            });
                        }
                    };
                    mediaRecorder.start(250);

                    return stream;
                } catch (err) {
                    console.error("Error accessing microphone:", err);
                    return null;
                }
            }

            on(event, callback) {
                this.events.set(event, callback);
            }

            emit(event, data) {
                const callback = this.events.get(event);
                if (callback) callback(data);
            }

            toggleMute() {
                this.isMuted = !this.isMuted;
                if (this.currentStream) {
                    this.currentStream.getAudioTracks().forEach((track) => {
                        track.enabled = !this.isMuted;
                    });
                }
                return this.isMuted;
            }



            // For playback (speaking mode)
            setupPlayback(audioElement) {
                const source = this.audioContext.createMediaElementSource(audioElement);
                this.playbackAnalyser = this.audioContext.createAnalyser();
                this.playbackAnalyser.fftSize = 256;
                this.playbackDataArray = new Uint8Array(
                    this.playbackAnalyser.frequencyBinCount
                );

                source.connect(this.playbackAnalyser);
                this.playbackAnalyser.connect(this.audioContext.destination);
            }

            getColor(varName) {
                return this.styles.getPropertyValue(varName).trim();
            }

            setupCanvas() {
                const size = 48;
                this.canvas.width = size;
                this.canvas.height = size;
                Object.assign(this.canvas.style, {
                    borderRadius: "50%",
                    backgroundColor: this.getColor("--surface-raised"),
                    transition: "all 0.3s ease"
                });
            }

            drawRocketIdle() {
                const centerX = this.canvas.width / 2;
                const centerY = this.canvas.height / 2;
                const radius = this.canvas.width * 0.3;
                const time = Date.now() / 1000;

                this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);

                // Outer ring with subtle pulse
                this.ctx.beginPath();
                const pulseOpacity = 0.3 + 0.1 * Math.sin(time * 2);
                this.ctx.strokeStyle = this.getColor("--glow-outer");
                this.ctx.lineWidth = 2;
                this.ctx.arc(centerX, centerY, radius, 0, Math.PI * 2);
                this.ctx.stroke();

                // Inner "core" with gentle glow
                const gradient = this.ctx.createRadialGradient(
                    centerX,
                    centerY,
                    0,
                    centerX,
                    centerY,
                    radius * 0.7
                );
                gradient.addColorStop(0, this.getColor("--glow-core"));
                gradient.addColorStop(1, "transparent");
                this.ctx.fillStyle = gradient;
                this.ctx.fill();
            }

            drawRocketListening() {
                if (this.canvas.width === 48) {
                    this.expandCanvas(200, 60);
                }

                const centerY = this.canvas.height / 2;
                this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);

                // Safety check for analyser
                if (!this.analyser) return;

                this.analyser.getByteFrequencyData(this.dataArray);

                const bars = 20;
                const barWidth = 4;
                const spacing = 6;
                const maxHeight = this.canvas.height * 0.8;

                this.ctx.fillStyle = this.getColor("--vis-listening");

                // Use actual frequency data for bar heights
                for (let i = 0; i < bars; i++) {
                    // Map our 20 bars to the frequency data (which is this.bufferLength long)
                    const dataIndex = Math.floor((i / bars) * this.bufferLength);
                    const value = this.dataArray[dataIndex];

                    // Normalize height (frequency data is 0-255)
                    const height = (value / 255) * maxHeight;

                    const x =
                        (this.canvas.width - bars * (barWidth + spacing)) / 2 +
                        i * (barWidth + spacing);
                    const y = centerY - height / 2;

                    this.ctx.fillRect(x, y, barWidth, height);
                }
            }

            drawRocketSpeaking() {
                if (this.canvas.width === 48) {
                    this.expandCanvas(200, 60);
                }

                const centerY = this.canvas.height / 2;
                this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);

                // Get playback audio data
                if (this.playbackAnalyser) {
                    this.playbackAnalyser.getByteTimeDomainData(this.playbackDataArray);
                }

                const points = [];
                const segments = 50;

                // Use actual waveform data if available
                for (let i = 0; i <= segments; i++) {
                    const x = (i / segments) * this.canvas.width;
                    let y;

                    if (this.playbackAnalyser) {
                        // Map our segments to the waveform data
                        const dataIndex = Math.floor(
                            (i / segments) * this.playbackDataArray.length
                        );
                        const value = this.playbackDataArray[dataIndex];
                        // Convert 0-255 to actual waveform (-1 to 1)
                        const normalizedValue = (value - 128) / 128;
                        y = centerY + normalizedValue * this.canvas.height * 0.3;
                    } else {
                        // Fallback to animation if no audio data
                        const time = Date.now() / 1000;
                        y =
                            centerY +
                            Math.sin(i * 0.2 + time * 2) * 10 +
                            Math.sin(i * 0.1 + time * 3) * 5;
                    }

                    points.push({ x, y });
                }

                // Draw the waveform
                this.ctx.beginPath();
                this.ctx.moveTo(points[0].x, points[0].y);

                for (let i = 1; i < points.length - 2; i++) {
                    const xc = (points[i].x + points[i + 1].x) / 2;
                    const yc = (points[i].y + points[i + 1].y) / 2;
                    this.ctx.quadraticCurveTo(points[i].x, points[i].y, xc, yc);
                }

                this.ctx.strokeStyle = this.getColor("--vis-speaking");
                this.ctx.lineWidth = 3;
                this.ctx.stroke();
            }

            expandCanvas(width, height) {
                this.canvas.width = width;
                this.canvas.height = height;
                Object.assign(this.canvas.style, {
                    borderRadius: "12px",
                    transform: "scale(1)",
                    transition: "all 0.3s ease"
                });
            }

            shrinkCanvas() {
                const size = 48;
                this.canvas.width = size;
                this.canvas.height = size;
                Object.assign(this.canvas.style, {
                    borderRadius: "50%",
                    transform: "scale(1)"
                });
            }

            // Method to handle mode changes with audio setup
            async setMode(mode) {
                if (this.audioContext && mode === 'idle') {
                    await this.audioContext.close();
                    this.audioContext = null;
                }

                if (mode === this.mode) return;

                // Cleanup previous mode
                if (this.currentStream) {
                    this.currentStream.getTracks().forEach((track) => track.stop());
                    this.currentStream = null;
                }

                this.mode = mode;
                if (mode === "idle") {
                    this.ws.close();
                    this.shrinkCanvas();
                    this.hideTranscript();
                } else if (mode === "listening") {
                    this.expandCanvas(200, 60);
                    this.showTranscript();
                    // Setup microphone input
                    this.currentStream = await this.setupRecording();
                } else if (mode === "speaking") {
                    this.expandCanvas(200, 60);
                    // Setup audio playback analysis if not already done
                    if (!this.playbackAnalyser && this.audioElement) {
                        this.setupPlayback(this.audioElement);
                    }
                }
            }

            showTranscript() {
                const transcriptArea = document.getElementById("transcript-area");
                if (transcriptArea) {
                    transcriptArea.classList.add("active");
                    this.transcriptActive = true;
                }
            }

            hideTranscript() {
                const transcriptArea = document.getElementById("transcript-area");
                if (transcriptArea) {
                    transcriptArea.classList.remove("active");
                    this.transcriptActive = false;
                }
            }

            updateTranscript(text) {
                const transcriptArea = document.getElementById("transcript-content");
                if (transcriptArea) {
                    transcriptArea.textContent = text;
                    transcriptArea.scrollTop = transcriptArea.scrollHeight;
                }
            }

            startAnimation() {
                let animationFrameId;
                const animate = () => {
                    switch (this.mode) {
                        case "idle":
                            this.drawRocketIdle();
                            break;
                        case "listening":
                            this.drawRocketListening();
                            break;
                        case "speaking":
                            this.drawRocketSpeaking();
                            break;
                    }
                    animationFrameId = requestAnimationFrame(animate);
                };
                animate();
                // cleanup
                this.stopAnimation = () => {
                    cancelAnimationFrame(animationFrameId);
                };
            }

            updateStatus(message) {
                const statusIndicator = document.getElementById("status-indicator");
                if (statusIndicator) {
                    statusIndicator.textContent = message;
                }
            }
        }

        function createIconElement(iconClass) {
            const icon = document.createElement('i');
            icon.className = iconClass;
            return icon;
        }

        function setButtonIcon(button, iconClass) {
            button.innerHTML = ''; // Clear existing content
            button.appendChild(createIconElement(iconClass));
        }

        function initializeUI() {
            // Create container
            container = document.createElement("div");
            container.id = "voicefaster-player";

            // Create header section
            const header = document.createElement("div");
            header.className = "player-header";

            // Create visualizer and make it globally accessible
            window.visualizer = new AudioVisualizer(container);
            header.appendChild(visualizer.canvas);

            // Add controls
            const controls = document.createElement("div");
            controls.className = "controls";













            // Create mic button
            const micButton = document.createElement("button");
            micButton.id = "mic-button";
            setButtonIcon(micButton, 'bi-mic-fill');
            micButton.addEventListener("click", async function (e) {
                // Resume AudioContext on user interaction
                if (visualizer.audioContext.state === "suspended") {
                    await visualizer.audioContext.resume();
                }

                if (e.shiftKey || visualizer.mode === "idle") {
                    toggleRecording();
                } else {
                    toggleMute(e);
                }
            });
            micButton.title = "Click to mute/unmute, Shift+Click to stop recording";

            // Create settings button
            const settingsButton = document.createElement("button");
            settingsButton.id = "settings-button";
            setButtonIcon(settingsButton, 'bi-gear-fill');
            settingsButton.title = "Settings";
            settingsButton.addEventListener("click", () => console.log("Settings clicked"));

            // Add buttons to controls
            controls.appendChild(micButton);
            controls.appendChild(settingsButton);
            header.appendChild(controls);

            // Add status indicator
            const status = document.createElement("div");
            status.id = "status-indicator";
            status.textContent = "Idle";
            header.appendChild(status);

            // Create transcript area
            const transcriptArea = document.createElement("div");
            transcriptArea.id = "transcript-area";
            transcriptArea.innerHTML = `
        <div id="transcript-content"></div>
        <div class="transcript-controls">
            <button id="send-transcript">Send</button>
            <button id="clear-transcript">Clear</button>
        </div>
    `;

            // Add everything to container
            container.appendChild(header);
            container.appendChild(transcriptArea);
            document.body.appendChild(container);

            // Add event listeners for transcript buttons only
            document.getElementById("send-transcript").addEventListener("click", sendTranscript);
            document.getElementById("clear-transcript").addEventListener("click", clearTranscript);

            // Initialize drag functionality
            initializeDrag(container);
        }


        function initializeDrag(element) {
            let isDragging = false;
            let currentX;
            let currentY;
            let initialX;
            let initialY;
            let xOffset = 0;
            let yOffset = 0;

            function dragStart(e) {
                // Ignore if target is a button
                if (e.target.tagName.toLowerCase() === "button") {
                    return;
                }

                initialX = e.clientX - xOffset;
                initialY = e.clientY - yOffset;

                if (
                    e.target === element ||
                    e.target.parentNode === element ||
                    e.target.parentNode.parentNode === element
                ) {
                    isDragging = true;
                }
            }

            function drag(e) {
                if (isDragging) {
                    e.preventDefault();
                    currentX = e.clientX - initialX;
                    currentY = e.clientY - initialY;

                    xOffset = currentX;
                    yOffset = currentY;

                    setTranslate(currentX, currentY, element);
                }
            }

            function dragEnd(e) {
                initialX = currentX;
                initialY = currentY;
                isDragging = false;
            }

            function setTranslate(xPos, yPos, el) {
                el.style.transform = `translate3d(${xPos}px, ${yPos}px, 0)`;
            }

            // Add the event listeners
            element.addEventListener("mousedown", dragStart, false);
            document.addEventListener("mousemove", drag, false);
            document.addEventListener("mouseup", dragEnd, false);
        }

        function toggleRecording() {
            const isListening = visualizer.mode === "listening";
            const newMode = isListening ? "idle" : "listening";
            visualizer.setMode(newMode);

            const status = document.getElementById("status-indicator");
            const micButton = document.getElementById("mic-button");

            if (isListening) {
                // Switching to idle
                status.textContent = "Idle";
                setButtonIcon(micButton, 'bi-mic-fill');
                micButton.classList.remove("active");
            } else {
                // Switching to listening
                status.textContent = visualizer.isMuted ? "Muted" : "Listening...";
                setButtonIcon(micButton, visualizer.isMuted ? 'bi-mic-mute-fill' : 'bi-mic-fill');
                micButton.classList.add("active");
            }
        }

        function toggleMute(event) {
            event.stopPropagation();

            if (visualizer.mode !== "listening") return;

            const isMuted = visualizer.toggleMute();
            const status = document.getElementById("status-indicator");
            const micButton = document.getElementById("mic-button");

            status.textContent = isMuted ? "Muted" : "Listening...";
            setButtonIcon(micButton, isMuted ? 'bi-mic-mute-fill' : 'bi-mic-fill');
        }

        function sendTranscript() {
            const content = document.getElementById("transcript-content").textContent;
            console.log("Sending transcript:", content);
            // Here you would integrate with TypingMind's input mechanism
            clearTranscript();
            visualizer.setMode("idle");
        }

        function clearTranscript() {
            document.getElementById("transcript-content").textContent = "";
        }

        // For demo purposes, add some sample transcript updates
//        function simulateTranscript() {
//            if (visualizer.mode === "listening") {
//                const words = [
//                    "Hello",
//                    "this",
//                    "is",
//                    "a",
//                    "test",
//                    "transcript",
//                    "being",
//                    "generated",
//                    "in",
//                    "real",
//                    "time"
//                ];
//                const currentContent = document.getElementById("transcript-content")
//                    .textContent;
//                const newWord = words[Math.floor(Math.random() * words.length)];
//                visualizer.updateTranscript(currentContent + " " + newWord);
//            }
//        }
//
//        // Simulate transcript updates every second when in listening mode
//        setInterval(simulateTranscript, 1000);
//
        // Initialize everything when the document is loaded
        document.addEventListener("DOMContentLoaded", initializeUI);

    </script>
</body>

</html>